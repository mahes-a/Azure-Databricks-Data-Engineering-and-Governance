# How to Enable Unity Catalog on Azure Databricks

Unity Catalog is a feature that provides cataloging and governance for the databricks lake house. It allows users to manage and access data across multiple workspaces and storage accounts, and supports data lineage, permissions, and insights.

To enable Unity Catalog on Azure Databricks, you need to create a Unity Catalog metastore, which is a top-level container for catalogs, schemas, and tables. You can share a single metastore across multiple Azure Databricks workspaces in an account, as long as they are in the same region.

## Prerequisites

- You must be an Azure Databricks account admin.

- The first Azure Databricks account admin must be a Microsoft Entra ID (formerly Azure Active Directory) Global Administrator at the time that they first log in to the Azure Databricks account console. Upon first login, that user becomes an Azure Databricks account admin and no longer needs the Microsoft Entra ID Global Administrator role to access the Azure Databricks account. The first account admin can assign users in the Microsoft Entra ID tenant as additional account admins (who can themselves assign more account admins). Additional account admins do not require specific roles in Microsoft Entra ID.

- The workspaces that you attach to the metastore must be on the Azure Databricks Premium plan.

- If you want to set up metastore-level root storage, you must have permission to create the following in your Azure tenant:

   - A storage account to use with Azure Data Lake Storage Gen2. See Create a storage account to use with Azure Data Lake Storage Gen2.
   - A new resource to hold a system-assigned managed identity. This requires that you be a Contributor or Owner of a resource group in any subscription in the tenant.

## Step 1 : Create a storage container for metastore-level managed storage

1. Create a storage account for Azure Data Lake Storage Gen2.

   <img width="575" alt="image" src="https://github.com/mahes-a/Azure-Databricks-Data-Engineering-and-Governance/assets/120069348/46f89861-819e-4b86-b7c7-2ef3e4ac9e2f">


This storage account will contain Unity Catalog managed tables and volumes. This must be an Azure Data Lake Storage Gen2 account in the same region as your Azure Databricks workspaces. See Create a storage account to use with Azure Data Lake Storage Gen2.

2. Create a storage container that will hold your managed tables and volume data at the metastore level.

 <img width="1195" alt="image" src="https://github.com/mahes-a/Azure-Databricks-Data-Engineering-and-Governance/assets/120069348/a85a11ed-694d-4e04-b7e6-0e0d7875274b">

You can create only one metastore per region. You must use the same region for your metastore and storage container.


## Step 2: Create an access connector for Azure Databricks

The Access Connector for Azure Databricks is a first-party Azure resource that lets you connect managed identities to an Azure Databricks account.

Each access connector for Azure Databricks can contain either one system-assigned managed identity or one user-assigned managed identity. If you want to use multiple managed identities, create a separate access connector for each.

1. Log in to the Azure Portal as a Contributor or Owner of a resource group.

2. Click + Create or Create a new resource.

3. Search for Access Connector for Azure Databricks and select it.

4. Click Create.

On the Basics tab, accept, select, or enter values for the following fields:

Subscription: This is the Azure subscription that the access connector will be created in. The default is the Azure subscription you are currently using. It can be any subscription in the tenant.
Resource group: This is the Azure resource group that the access connector will be created in.
Name: Enter a name that indicates the purpose of the connector.
Region: This should be the same region as the storage account that you will connect to.
Click Review + create.

<img width="632" alt="image" src="https://github.com/mahes-a/Azure-Databricks-Data-Engineering-and-Governance/assets/120069348/f43dd84a-001f-4fd0-b13c-a554588382ef">


5. When you see the Validation Passed message, click Create.

6. When the deployment succeeds, the access connector is deployed with a system-assigned managed identity.

7. When the deployment is complete, click Go to resource.

8. Make a note of the Resource ID.

<img width="1197" alt="image" src="https://github.com/mahes-a/Azure-Databricks-Data-Engineering-and-Governance/assets/120069348/c64c2db0-e3aa-49b2-aef4-3ef3e9bd4958">

## Step 3: Assign role for the access connector

1. Open the Storage account crreated in previous step
2. Go to Access Control , Add role assignment

   <img width="964" alt="image" src="https://github.com/mahes-a/Azure-Databricks-Data-Engineering-and-Governance/assets/120069348/c0e10083-398f-4ea5-8059-c169e65e2e7f">

3.  Select the Storage Blob Data Contributor role and add the access connector to this role

   <img width="1195" alt="image" src="https://github.com/mahes-a/Azure-Databricks-Data-Engineering-and-Governance/assets/120069348/c5511140-7ebb-4bc2-9723-8dfbe51607ba">


## Step 4: Create the metastore and enable Delta Sharing

Before you begin read the prereqs from [here](https://learn.microsoft.com/en-us/azure/databricks/data-governance/unity-catalog/create-metastore#before-you-begin)

1. As an account admin, log in to the account console.
2. Click on **Data**->**Create Metastore**

   <img width="1192" alt="image" src="https://github.com/mahes-a/Azure-Databricks-Data-Engineering-and-Governance/assets/120069348/9eae3bc2-668b-4b56-bc1c-787f07f3e90f">

4. Provide a name and a region for the metastore. The name must be unique within the account and the region.
5. Provide an ADLS Gen2 path for the metastore created in step 1. This is where the metadata and the data for managed tables and managed volumes will be stored.
6. Provide the resource id of the access connector created in Step 2

 <img width="506" alt="image" src="https://github.com/mahes-a/Azure-Databricks-Data-Engineering-and-Governance/assets/120069348/d524dcc3-9aed-4b1c-8bd0-2d2dbf871d4a">

 7. Open the Metastore created from Data-> Metastores and ensure to "Enable Delta Sharing to allow a Databricks user to share data outside their organization"

    <img width="526" alt="image" src="https://github.com/mahes-a/Azure-Databricks-Data-Engineering-and-Governance/assets/120069348/30970a43-4cee-40b3-bdd5-7b7d2dd8654b">


## Step 5: Assign the Unity Catalog resource to a workspace

If you have not created a Azure Databricks workspace , Please follow the steps [here](https://learn.microsoft.com/en-us/azure/databricks/getting-started/#use-the-portal-to-create-an-azure-databricks-workspace)

1. As an account admin, log in to the account console.
2. Click Catalog icon Data.
3. Click the metastore name where workspace should be assigned.

   <img width="1034" alt="image" src="https://github.com/mahes-a/Azure-Databricks-Data-Engineering-and-Governance/assets/120069348/6a34a03b-3e00-4e88-af0c-f2a871778c1a">

5. Click the Workspaces tab.
6. Click Assign to workspaces.

   <img width="1043" alt="image" src="https://github.com/mahes-a/Azure-Databricks-Data-Engineering-and-Governance/assets/120069348/3356163a-136a-4870-973e-4c7f96fe14ea">

8. Select one or more workspaces. You can type part of the workspace name to filter the list.

   <img width="957" alt="image" src="https://github.com/mahes-a/Azure-Databricks-Data-Engineering-and-Governance/assets/120069348/f2a6aa78-4eba-4a70-9a5f-2318736fbaea">

Click Assign.
On the confirmation dialog, click Enable.

